#!/usr/bin/env python3
"""
Test completo del pipeline de compilaci√≥n con c√≥digo v√°lido
"""

from main import LexicalAnalyzer, Parser, SemanticAnalyzer, CodeGenerator, VirtualMachine

def test_complete_pipeline():
    """Prueba completa del pipeline con c√≥digo sin errores"""
    
    # C√≥digo de prueba completamente v√°lido
    source_code = '''
int main() {
    int x = 10;
    int y = 20;
    int result = x + y;
    
    if (result > 15) {
        int temp = 5;
        result = result + temp;
    }
    
    return result;
}
'''
    
    print("=" * 80)
    print("TEST COMPLETO DEL PIPELINE DE COMPILACI√ìN")
    print("=" * 80)
    
    # Inicializar todos los componentes
    lexer = LexicalAnalyzer()
    semantic = SemanticAnalyzer()
    codegen = CodeGenerator()
    vm = VirtualMachine()
    
    print("\n1. AN√ÅLISIS L√âXICO")
    print("-" * 40)
    lexer.analyze(source_code)
    print(f"‚úÖ Tokens generados: {len(lexer.tokens)}")
    print(f"‚úÖ Errores l√©xicos: {len(lexer.errors)}")
    
    print("\n2. AN√ÅLISIS SEM√ÅNTICO")
    print("-" * 40)
    semantic_errors = semantic.analyze(lexer.tokens)
    print(f"‚úÖ Variables declaradas: {sum(len(symbols) for symbols in semantic.scopes.values())}")
    print(f"‚úÖ Errores sem√°nticos: {len(semantic_errors)}")
    
    if semantic_errors:
        print("‚ùå Errores sem√°nticos detectados:")
        for error in semantic_errors:
            print(f"   - {error}")
        return
    
    print("\n3. PARSING (AST)")
    print("-" * 40)
    parser = Parser(lexer.tokens)
    ast = parser.parse()
    print(f"‚úÖ AST construido: {ast.type}")
    print(f"‚úÖ Nodos totales: {count_nodes(ast)}")
    print(f"‚úÖ Errores parsing: {len(parser.errors)}")
    
    if parser.errors:
        print("‚ùå Errores de parsing detectados:")
        for error in parser.errors:
            print(f"   - {error}")
        return
    
    print("\n4. GENERACI√ìN DE C√ìDIGO")
    print("-" * 40)
    instructions = codegen.generate(ast)
    print(f"‚úÖ Instrucciones TAC: {len(instructions)}")
    
    print("\n5. EJECUCI√ìN EN M√ÅQUINA VIRTUAL")
    print("-" * 40)
    vm.load_instructions(instructions)
    vm.run()
    print(f"‚úÖ Ejecuci√≥n completada")
    print(f"‚úÖ Variables en memoria: {len(vm.memory)}")
    print(f"‚úÖ Estado final VM: {vm.memory}")
    
    # Resumen final
    print("\n" + "=" * 80)
    print("RESUMEN DE LA COMPILACI√ìN")
    print("=" * 80)
    
    print(f"üìä ESTAD√çSTICAS:")
    print(f"   ‚Ä¢ Tokens procesados: {len(lexer.tokens)}")
    print(f"   ‚Ä¢ Variables declaradas: {sum(len(symbols) for symbols in semantic.scopes.values())}")
    print(f"   ‚Ä¢ Nodos AST: {count_nodes(ast)}")
    print(f"   ‚Ä¢ Instrucciones TAC: {len(instructions)}")
    print(f"   ‚Ä¢ Variables en ejecuci√≥n: {len(vm.memory)}")
    
    print(f"\nüîç RESULTADOS:")
    if 'result' in vm.memory:
        print(f"   ‚Ä¢ Resultado final: {vm.memory['result']}")
    if 'x' in vm.memory and 'y' in vm.memory:
        print(f"   ‚Ä¢ x = {vm.memory['x']}, y = {vm.memory['y']}")
    if vm.stack:
        print(f"   ‚Ä¢ Valor de retorno: {vm.stack[-1]}")
    
    print(f"\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
    
    # Mostrar el bytecode generado
    print(f"\nüìù BYTECODE GENERADO:")
    print("-" * 50)
    for i, instr in enumerate(instructions):
        if instr.operand:
            print(f"  {i:2d}: {instr.opcode:<15} {instr.operand}")
        else:
            print(f"  {i:2d}: {instr.opcode:<15}")

def count_nodes(node):
    """Cuenta recursivamente los nodos del AST"""
    count = 1
    for child in node.children:
        count += count_nodes(child)
    return count

def test_simple_math():
    """Prueba simple de operaciones matem√°ticas"""
    
    print(f"\n{'='*80}")
    print("TEST SIMPLE: OPERACIONES MATEM√ÅTICAS")
    print("=" * 80)
    
    source_code = '''
int main() {
    int a = 5;
    int b = 3;
    int c = a + b;
    return c;
}
'''
    
    # Pipeline completo
    lexer = LexicalAnalyzer()
    semantic = SemanticAnalyzer()
    codegen = CodeGenerator()
    vm = VirtualMachine()
    
    # Ejecutar pipeline
    lexer.analyze(source_code)
    semantic.analyze(lexer.tokens)
    
    parser = Parser(lexer.tokens)
    ast = parser.parse()
    instructions = codegen.generate(ast)
    vm.load_instructions(instructions)
    vm.run()
    
    print(f"C√≥digo: 5 + 3 = {vm.memory.get('c', 'ERROR')}")
    print(f"Memoria: {vm.memory}")
    print(f"Retorno: {vm.stack[-1] if vm.stack else 'EMPTY'}")

if __name__ == '__main__':
    test_complete_pipeline()
    test_simple_math()
